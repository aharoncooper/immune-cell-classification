{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOPcWdZqjKV84fmoxEA31ET",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aharoncooper/immune-cell-classification/blob/main/classification_2nd_try.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Kaggle API\n",
        "!pip install kaggle\n",
        "\n",
        "# Set up Kaggle credentials (ensure you have uploaded `kaggle.json`)\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset directly to Colab\n",
        "!kaggle datasets download masoudnickparvar/white-blood-cells-dataset --unzip -p /content/white_blood_cells\n",
        "\n",
        "# Verify the dataset\n",
        "import os\n",
        "files = os.listdir(\"/content/white_blood_cells\")\n",
        "print(\"Files in dataset directory:\", files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffq_ayW5_bdp",
        "outputId": "5c489453-2641-40c8-e780-c48be3f95dac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "mv: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/masoudnickparvar/white-blood-cells-dataset\n",
            "License(s): copyright-authors\n",
            "Downloading white-blood-cells-dataset.zip to /content/white_blood_cells\n",
            " 98% 491M/499M [00:07<00:00, 72.2MB/s]\n",
            "100% 499M/499M [00:07<00:00, 68.0MB/s]\n",
            "Files in dataset directory: ['Test-A', 'Train', 'Test-B']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the path where the folders are located\n",
        "base_path = \"/content/white_blood_cells\"  # Change this to your actual path if needed\n",
        "\n",
        "# Define the old and new folder names\n",
        "old_name_a = os.path.join(base_path, \"Test-A\")\n",
        "new_name_a = os.path.join(base_path, \"Valid\")\n",
        "\n",
        "old_name_b = os.path.join(base_path, \"Test-B\")\n",
        "new_name_b = os.path.join(base_path, \"Test\")\n",
        "\n",
        "# Rename the folders\n",
        "os.rename(old_name_a, new_name_a)\n",
        "os.rename(old_name_b, new_name_b)\n",
        "\n",
        "print(\"Folders renamed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86z6SUz4_3Nk",
        "outputId": "6dd3a181-f6cc-4b7a-f65c-c0c93774db15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders renamed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/white_blood_cells\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OOA4YcEAFXh",
        "outputId": "83392a76-3636-4301-d804-8bf82dd0c6fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test  Train  Valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the paths for the folders\n",
        "valid_path = \"/content/white_blood_cells/Valid/Basophil\"\n",
        "test_path = \"/content/white_blood_cells/Test/Basophil\"\n",
        "\n",
        "# Create the Basophil folder in the test directory if it doesn't exist\n",
        "os.makedirs(test_path, exist_ok=True)\n",
        "\n",
        "# List all images in the valid/Basophil folder\n",
        "basophil_images = os.listdir(valid_path)\n",
        "\n",
        "# Sort the images (optional, if you want to pick them in a specific order)\n",
        "basophil_images.sort()\n",
        "\n",
        "# Move the first 45 images from valid/Basophil to test/Basophil\n",
        "for image in basophil_images[:45]:\n",
        "    source = os.path.join(valid_path, image)\n",
        "    destination = os.path.join(test_path, image)\n",
        "    shutil.move(source, destination)\n",
        "\n",
        "print(\"45 Basophil images moved to the Test folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM0_b7TxAInh",
        "outputId": "78fc96fb-6f55-46c4-ac6a-884dcfdc4efc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45 Basophil images moved to the Test folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the paths for the folders\n",
        "valid_path = \"/content/white_blood_cells/Valid/Eosinophil\"\n",
        "test_path = \"/content/white_blood_cells/Test/Eosinophil\"\n",
        "\n",
        "# Create the Eosinophil folder in the test directory if it doesn't exist\n",
        "os.makedirs(test_path, exist_ok=True)\n",
        "\n",
        "# List all images in the valid/Eosinophil folder\n",
        "eosinophil_images = os.listdir(valid_path)\n",
        "\n",
        "# Check if there are at least 160 images in valid/Eosinophil\n",
        "if len(eosinophil_images) >= 160:\n",
        "    # Move the first 160 images from valid/Eosinophil to test/Eosinophil\n",
        "    for image in eosinophil_images[:160]:\n",
        "        source = os.path.join(valid_path, image)\n",
        "        destination = os.path.join(test_path, image)\n",
        "        shutil.move(source, destination)\n",
        "    print(\"160 Eosinophil images moved to the Test folder.\")\n",
        "else:\n",
        "    print(\"Error: Not enough images in valid/Eosinophil to move 160 images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmAvVWYaBl9k",
        "outputId": "c96805d5-4985-40f0-bf74-2f9aa744d7f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160 Eosinophil images moved to the Test folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the paths for the folders\n",
        "valid_path = \"/content/white_blood_cells/Valid/Monocyte\"\n",
        "test_path = \"/content/white_blood_cells/Test/Monocyte\"\n",
        "\n",
        "# Create the Monocyte folder in the test directory if it doesn't exist\n",
        "os.makedirs(test_path, exist_ok=True)\n",
        "\n",
        "# List all images in the valid/Monocyte folder\n",
        "monocyte_images = os.listdir(valid_path)\n",
        "\n",
        "# Check if there are at least 167 images in valid/Monocyte\n",
        "if len(monocyte_images) >= 167:\n",
        "    # Move the first 167 images from valid/Monocyte to test/Monocyte\n",
        "    for image in monocyte_images[:167]:\n",
        "        source = os.path.join(valid_path, image)\n",
        "        destination = os.path.join(test_path, image)\n",
        "        shutil.move(source, destination)\n",
        "    print(\"167 Monocyte images moved to the Test folder.\")\n",
        "else:\n",
        "    print(\"Error: Not enough images in valid/Monocyte to move 167 images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2hAEKwcBt3O",
        "outputId": "a43f4f22-ee3e-45c8-b753-ce12b0974131"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "167 Monocyte images moved to the Test folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install fastai\n",
        "!pip install fastai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovAsS2F4DpSo",
        "outputId": "e5fc6618-6314-469e-9621-6f6d3fe6068a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.10/dist-packages (2.7.18)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai) (24.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai) (24.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.7.22)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.20.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai) (3.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai) (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fastai) (2.32.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai) (6.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai) (11.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastai) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai) (1.13.1)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.5)\n",
            "Requirement already satisfied: torch<2.6,>=1.10 in /usr/local/lib/python3.10/dist-packages (from fastai) (2.5.1+cu121)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.15.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (4.66.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.26.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.6,>=1.10->fastai) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.6,>=1.10->fastai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.6,>=1.10->fastai) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.6,>=1.10->fastai) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.6,>=1.10->fastai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<2.6,>=1.10->fastai) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4->fastai) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z2jEL4dN-Mt",
        "outputId": "0033fa35-2b0a-4d36-8f89-832729eb1821"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "import wandb\n",
        "\n"
      ],
      "metadata": {
        "id": "JzSoDCNnNEy1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "wGYkz24RNGle",
        "outputId": "7bd7d444-cbbe-4a96-f4e6-b5c4b0912a55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #very basic 1st use works\n",
        "\n",
        "# from collections import Counter\n",
        "# import random\n",
        "\n",
        "# # Function to count class distribution\n",
        "# def count_classes(items):\n",
        "#     return Counter([Path(item).parent.name for item in items])\n",
        "\n",
        "# # Oversampling function\n",
        "# def oversample_classes(items, class_counts, target_count):\n",
        "#     oversampled = []\n",
        "#     for cls, count in class_counts.items():\n",
        "#         cls_items = [item for item in items if Path(item).parent.name == cls]\n",
        "#         oversampled.extend(cls_items)\n",
        "#         if count < target_count:\n",
        "#             oversampled.extend(random.choices(cls_items, k=target_count - count))  # Oversample the smaller classes\n",
        "#     return oversampled\n",
        "\n",
        "# # Apply oversampling to the training set\n",
        "# train_items = dls.train_ds.items\n",
        "# train_class_counts = count_classes(train_items)\n",
        "# target_count = max(train_class_counts.values())  # Use the largest class size for oversampling\n",
        "# oversampled_train_items = oversample_classes(train_items, train_class_counts, target_count)\n",
        "# oversampled_class_counts = count_classes(oversampled_train_items)\n",
        "# print(f\"Train class counts after oversampling: {oversampled_class_counts}\")\n",
        "\n",
        "# # Update DataBlock to use the oversampled dataset\n",
        "# oversampled_dblock = DataBlock(\n",
        "#     blocks=(ImageBlock, CategoryBlock),\n",
        "#     get_items=lambda _: oversampled_train_items,  # Use oversampled training dataset\n",
        "#     splitter=GrandparentSplitter(train_name='Train', valid_name='Valid'),  # Keep valid split unchanged\n",
        "#     get_y=parent_label,\n",
        "#     item_tfms=Resize(224),\n",
        "#     batch_tfms=aug_transforms()\n",
        "# )\n",
        "\n",
        "# # Recreate DataLoaders with oversampled training data\n",
        "# dls = oversampled_dblock.dataloaders(data_dir, bs=32)\n",
        "\n",
        "# # Model definition with L2 Regularization\n",
        "# model = vision_learner(\n",
        "#     dls,\n",
        "#     resnet18,\n",
        "#     metrics=[accuracy],\n",
        "#     loss_func=CrossEntropyLossFlat(),\n",
        "#     wd=1e-4  # L2 regularization\n",
        "# )\n",
        "\n",
        "# # Train the model with oversampled data\n",
        "# model.fit_one_cycle(10, lr_max=0.01)\n"
      ],
      "metadata": {
        "id": "mGRnUngirxiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.vision.all import *\n",
        "import wandb\n",
        "import random\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Initialize the W&B run\n",
        "wandb.init(\n",
        "    project=\"white_blood_cells\",\n",
        "    config={\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"epochs\": 10,\n",
        "        \"weight_decay\": 1e-4,  # L2 regularization\n",
        "    },\n",
        ")\n",
        "\n",
        "# Replace 'data_dir' with the path to your dataset folder\n",
        "data_dir = Path('/content/white_blood_cells')\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "DEVnE-96vkN6",
        "outputId": "e786bf5e-e07c-4e4a-c610-e9fa2840813e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:0dwxpgb2) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_score</td><td>▂▄▁▅█▆█</td></tr><tr><td>precision</td><td>▁▃▂▅▇▆█</td></tr><tr><td>recall</td><td>▂▅▁▅█▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_score</td><td>0.98505</td></tr><tr><td>precision</td><td>0.98741</td></tr><tr><td>recall</td><td>0.98412</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">skilled-microwave-41</strong> at: <a href='https://wandb.ai/cooperaharon49-bar-ilan-university/white_blood_cells/runs/0dwxpgb2' target=\"_blank\">https://wandb.ai/cooperaharon49-bar-ilan-university/white_blood_cells/runs/0dwxpgb2</a><br/> View project at: <a href='https://wandb.ai/cooperaharon49-bar-ilan-university/white_blood_cells' target=\"_blank\">https://wandb.ai/cooperaharon49-bar-ilan-university/white_blood_cells</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241211_124256-0dwxpgb2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:0dwxpgb2). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241211_125755-8rzysa0p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cooperaharon49-bar-ilan-university/white_blood_cells/runs/8rzysa0p' target=\"_blank\">misty-waterfall-42</a></strong> to <a href='https://wandb.ai/cooperaharon49-bar-ilan-university/white_blood_cells' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cooperaharon49-bar-ilan-university/white_blood_cells' target=\"_blank\">https://wandb.ai/cooperaharon49-bar-ilan-university/white_blood_cells</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cooperaharon49-bar-ilan-university/white_blood_cells/runs/8rzysa0p' target=\"_blank\">https://wandb.ai/cooperaharon49-bar-ilan-university/white_blood_cells/runs/8rzysa0p</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7aa20c28de50>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to count class distribution\n",
        "def count_classes(items):\n",
        "    return Counter([Path(item).parent.name for item in items])\n",
        "\n",
        "# DataBlock respecting folder structure\n",
        "dblock = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,  # Get all image files\n",
        "    splitter=GrandparentSplitter(train_name='Train', valid_name='Valid'),  # Use existing folder split\n",
        "    get_y=parent_label,\n",
        "    item_tfms=Resize(224),\n",
        "    batch_tfms=aug_transforms()  # Data augmentation\n",
        ")\n",
        "\n",
        "# Create initial DataLoaders to access train dataset\n",
        "dls = dblock.dataloaders(data_dir, bs=32)\n",
        "\n",
        "# Separate train and valid items\n",
        "train_items = dls.train_ds.items  # Access only train items\n",
        "valid_items = dls.valid_ds.items\n",
        "\n",
        "# Print initial class distribution\n",
        "print(f\"Train class counts before oversampling: {count_classes(train_items)}\")\n",
        "print(f\"Valid class counts: {count_classes(valid_items)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QkEEbnKvruY",
        "outputId": "bad9189e-ccc5-40fd-fac6-8adaa2bfe296"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train class counts before oversampling: Counter({'Neutrophil': 6231, 'Lymphocyte': 2427, 'Eosinophil': 744, 'Monocyte': 561, 'Basophil': 212})\n",
            "Valid class counts: Counter({'Neutrophil': 2660, 'Lymphocyte': 1034, 'Eosinophil': 162, 'Monocyte': 67, 'Basophil': 44})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Compute target count for oversampling\n",
        "# train_class_counts = count_classes(train_items)\n",
        "# target_count = max(train_class_counts.values())  # Use the largest class size for oversampling\n",
        "\n",
        "# # Oversampling function\n",
        "# def oversample_classes(items, class_counts, target_count):\n",
        "#     oversampled = []\n",
        "#     for cls, count in class_counts.items():\n",
        "#         cls_items = [item for item in items if Path(item).parent.name == cls]\n",
        "#         oversampled.extend(cls_items)\n",
        "#         if count < target_count:\n",
        "#             oversampled.extend(random.choices(cls_items, k=target_count - count))  # Oversample the smaller classes\n",
        "#     return oversampled\n",
        "\n",
        "# # Apply oversampling to the training set\n",
        "# oversampled_train_items = oversample_classes(train_items, train_class_counts, target_count)\n",
        "# oversampled_class_counts = count_classes(oversampled_train_items)\n",
        "\n",
        "# # Print out the class distribution after oversampling\n",
        "# print(f\"Train class counts after oversampling: {oversampled_class_counts}\")\n"
      ],
      "metadata": {
        "id": "_UVm41U2vz1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create a new DataBlock using the oversampled training items\n",
        "# oversampled_dblock = DataBlock(\n",
        "#     blocks=(ImageBlock, CategoryBlock),\n",
        "#     get_items=lambda _: oversampled_train_items,  # Use oversampled training dataset\n",
        "#     splitter=GrandparentSplitter(train_name='Train', valid_name='Valid'),  # Keep valid split unchanged\n",
        "#     get_y=parent_label,\n",
        "#     item_tfms=Resize(224),\n",
        "#     batch_tfms=aug_transforms()\n",
        "# )\n",
        "\n",
        "# # Verify the splitting process after oversampling\n",
        "# image_files = get_image_files(data_dir)\n",
        "# splitter = GrandparentSplitter(train_name='Train', valid_name='Valid')\n",
        "# train_files, valid_files = splitter(image_files)\n",
        "\n",
        "# print(f\"Number of training files: {len(train_files)}\")\n",
        "# print(f\"Number of validation files: {len(valid_files)}\")\n"
      ],
      "metadata": {
        "id": "qcCOXptjv3Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weighted loss function\n",
        "class WeightedCrossEntropy(nn.Module):\n",
        "    def __init__(self, weights):\n",
        "        super().__init__()\n",
        "        self.weights = torch.tensor(list(weights.values()), dtype=torch.float)\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return F.cross_entropy(input, target, weight=self.weights.to(input.device))\n",
        "\n",
        "# Compute class weights for the loss function\n",
        "train_class_counts = count_classes(train_items)  # Use original class counts (no oversampling)\n",
        "total_samples = sum(train_class_counts.values())\n",
        "class_weights = {cls: total_samples / (len(train_class_counts) * count) for cls, count in train_class_counts.items()}\n",
        "weighted_loss = WeightedCrossEntropy(class_weights)\n",
        "\n",
        "# # Compute class weights for the loss function if using oversampling\n",
        "# total_samples = sum(oversampled_class_counts.values())\n",
        "# class_weights = {cls: total_samples / (len(oversampled_class_counts) * count) for cls, count in oversampled_class_counts.items()}\n",
        "# weighted_loss = WeightedCrossEntropy(class_weights)\n"
      ],
      "metadata": {
        "id": "IysfhjXqv7Nl"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition with L2 Regularization\n",
        "model = vision_learner(\n",
        "    dls,\n",
        "    resnet18,\n",
        "    metrics=[accuracy],\n",
        "    loss_func=weighted_loss,\n",
        "    wd=1e-4  # L2 regularization\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZufCs7GNv91i"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom callback for precision, recall, and F1-score\n",
        "class MetricsLogger(Callback):\n",
        "    def __init__(self):\n",
        "        self.y_true = []\n",
        "        self.y_pred = []\n",
        "\n",
        "    def after_validate(self):\n",
        "        print(f\"Validation completed. Calculating metrics...\")\n",
        "\n",
        "        # Compute precision, recall, and F1-score after validation\n",
        "        precision = precision_score(self.y_true, self.y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(self.y_true, self.y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(self.y_true, self.y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "        # Log the metrics to Weights & Biases\n",
        "        wandb.log({\"precision\": precision, \"recall\": recall, \"f1_score\": f1})\n",
        "\n",
        "    def before_validate(self):\n",
        "        self.y_true = []\n",
        "        self.y_pred = []\n",
        "\n",
        "    def after_batch(self):\n",
        "        if not self.training:\n",
        "            # Clone `self.pred` and `self.yb` to avoid interference\n",
        "            preds = self.pred.clone().detach()\n",
        "            targets = self.yb[0].clone().detach()\n",
        "\n",
        "            # Store predictions and targets for metrics calculation\n",
        "            self.y_true.extend(targets.cpu().numpy())\n",
        "            self.y_pred.extend(preds.argmax(dim=1).cpu().numpy())\n"
      ],
      "metadata": {
        "id": "MAZdjvQ6wAQZ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with updated callback for custom metrics\n",
        "model.fit_one_cycle(10, lr_max=0.01, cbs=[MetricsLogger()])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "uAEhYAgYwDAn",
        "outputId": "002fbd7a-5373-497d-a815-1b36de69a2fd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.302030</td>\n",
              "      <td>0.223804</td>\n",
              "      <td>0.945803</td>\n",
              "      <td>01:48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.315504</td>\n",
              "      <td>0.144371</td>\n",
              "      <td>0.960928</td>\n",
              "      <td>01:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.249329</td>\n",
              "      <td>0.470821</td>\n",
              "      <td>0.912528</td>\n",
              "      <td>01:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.185379</td>\n",
              "      <td>0.310855</td>\n",
              "      <td>0.926645</td>\n",
              "      <td>01:46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.146851</td>\n",
              "      <td>0.057074</td>\n",
              "      <td>0.978069</td>\n",
              "      <td>01:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.108787</td>\n",
              "      <td>0.091473</td>\n",
              "      <td>0.967482</td>\n",
              "      <td>01:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.065664</td>\n",
              "      <td>0.044822</td>\n",
              "      <td>0.981094</td>\n",
              "      <td>01:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.042210</td>\n",
              "      <td>0.048486</td>\n",
              "      <td>0.980590</td>\n",
              "      <td>01:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.039049</td>\n",
              "      <td>0.051955</td>\n",
              "      <td>0.981598</td>\n",
              "      <td>01:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.047346</td>\n",
              "      <td>0.060947</td>\n",
              "      <td>0.978825</td>\n",
              "      <td>01:45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation completed. Calculating metrics...\n",
            "Validation completed. Calculating metrics...\n",
            "Validation completed. Calculating metrics...\n",
            "Validation completed. Calculating metrics...\n",
            "Validation completed. Calculating metrics...\n",
            "Validation completed. Calculating metrics...\n",
            "Validation completed. Calculating metrics...\n",
            "Validation completed. Calculating metrics...\n",
            "Validation completed. Calculating metrics...\n",
            "Validation completed. Calculating metrics...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model after training\n",
        "model_path = '/content/white_blood_cells/best_model.pth'\n",
        "model.save(model_path)  # Save the model weights\n",
        "\n",
        "# Optionally, upload it to WandB\n",
        "wandb.save(model_path)  # This will upload it to your wandb project\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bsy1UxUV7Dkj",
        "outputId": "61350ed8-f0f3-496f-e4fc-2d06999c5f3b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}